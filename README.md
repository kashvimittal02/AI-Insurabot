# ğŸ“ AI-Insurabot (HackRx Project)

AI-Insurabot is a **document question-answering system** that allows users to upload files (PDF, Word, Email, etc.) and query them in **natural language**.  
It uses a **retrieval-augmented generation (RAG)** pipeline to fetch the most relevant information from documents and provide **accurate, context-based answers** â€” saving users from reading lengthy files manually.

---

## ğŸš€ Features
- ğŸ“‚ **Multi-format support**: Upload and process **PDF, Word (.docx), Email (.eml)** documents.  
- ğŸ” **Semantic Search**: Uses **embeddings + FAISS vector database** to retrieve the most relevant text chunks.  
- ğŸ¤– **RAG Pipeline**: Retrieved chunks are passed to an LLM (Ollama running **LLaMA 3.2**) for generating answers.  
- âš¡ **Backend**: Modular **FastAPI** service for document ingestion, embeddings, and query answering.  
- ğŸ’» **Frontend**: Simple **React/HTML UI** for uploading documents and asking questions.  
- ğŸ§© **Extensible**: Can be easily extended with new file parsers or connected to cloud-based LLM APIs.

---

## ğŸ› ï¸ Tech Stack
- **Backend**: Python, FastAPI, LangChain, FAISS, Ollama (LLaMA 3.2)  
- **Frontend**: React + HTML  
- **Vector DB**: FAISS (local)  
- **Workflow**: Retrieval-Augmented Generation (RAG)  
- **Document Parsing**: PDF, Word (.docx), Email (.eml)  

---

## ğŸ“‚ Project Structure
hackrx_full_project/
â”‚â”€â”€ backend/ # FastAPI backend (document ingestion, embeddings, QA pipeline)
â”‚â”€â”€ frontend/ # React/HTML frontend (file upload + query interface)
â”‚â”€â”€ models/ # Placeholder for embeddings/LLM configs
â”‚â”€â”€ data/ # Sample documents (PDF/Word/Email)
â”‚â”€â”€ tests/ # Unit and integration tests
â”‚â”€â”€ requirements.txt # Python dependencies
â”‚â”€â”€ README.md # Project description (this file)

---

## âš¡ Getting Started

### 1ï¸âƒ£ Clone the Repository
git clone https://github.com/kashvimittal02/AI-Insurabot.git
cd AI-Insurabot
2ï¸âƒ£ Setup Backend (FastAPI)
bash
Copy code
cd backend
python -m venv .venv
.venv\Scripts\activate     # On Windows
pip install -r requirements.txt

# Run FastAPI server
uvicorn main:app --reload --port 8000
API will be available at: http://localhost:8000
Swagger docs at: http://localhost:8000/docs

3ï¸âƒ£ Setup Frontend (React)
bash
Copy code
cd frontend
npm install
npm start
UI will be available at: http://localhost:3000

ğŸ” Example Workflow
Upload a PDF/Word/Email document via the frontend.

Backend parses and chunks the text, creates embeddings, and stores them in FAISS.

User asks a natural language question in the frontend.

Backend retrieves top-k relevant chunks, sends them to LLaMA 3.2 via Ollama.

The model generates a context-aware answer and sends it back to the user.

ğŸ¯ Skills & Tools Learned
Semantic Search & Embeddings (LangChain, FAISS, sentence-transformers)

Vector Databases and similarity search

LLM Integration (Ollama + LLaMA 3.2)

RAG workflow design

Backend Development (FastAPI APIs for ingestion & QA)

Frontend Development (React UI for uploads & queries)

ğŸ† HackRx Journey
Version 1: Local demo with LangChain, FAISS, Ollama (LLaMA 3.2).

Version 2: Extended into a FastAPI backend + React frontend â†’ more modular, usable, and closer to a real product.

ğŸ“œ License
MIT License â€“ feel free to use and modify for your own projects.
